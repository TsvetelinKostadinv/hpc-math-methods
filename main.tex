% !TeX root = main.tex

\documentclass[a4paper, oneside]{article}
% \usepackage[margin=2cm,bottom=4cm]{geometry}
\addtolength{\oddsidemargin}{-.25in}
\addtolength{\evensidemargin}{-.25in}
\addtolength{\textwidth}{1.in}

\usepackage{tsetsko-style}
\addbibresource{ref.bib}

\title{Final Project}
\date{\today}

\author{Tsvetelin Kostadinov}
\newcommand{\univname}{Sofia University "St. Kliment Ohridski"\\Faculty of mathematics and informatics}

\begin{document}
\include{title_page}

\begin{problem}\label{ex:1}
Show that the Lagrange form for $P_n$ can be rewritten as
\begin{equation}
    P_n(x) = w(x).\sum_{j=0}^n \frac{\beta_j}{x - x_j}f(x_j)
\end{equation}
where for any $n \in \N$, $j \in \N$ and $j \leq n$
\begin{align}
    P_n(x) = \sum_{j=0}^n l_j(x).f(x_j)                         \\
    l_j(x) = \prod_{k=0 \atop k \neq j} \frac{x-x_k}{x_j - x_k} \\
    w(x) = \prod_{k=0}^n (x - x_k)                              \\
    \beta_j = \frac{1}{\prod_{k=0 \atop k\neq j}^n (x_j - x_k)}
\end{align}
\end{problem}
\begin{solution}
    First, let us denote $f(x_i) = f_i$. We know that:
    \begin{align}
        P_n(x) = \sum_{j=0}^n l_j(x)f_j \\
        = \sum_{j=0}^n f_j \prod_{k=0 \atop k \neq j}^n \frac{x-x_k}{x_j - x_k}
    \end{align}
    for any $j$ we can rewrite $l_j$ in the form:
    \begin{align}
        l_j(x) = \prod_{k=0 \atop k \neq j}^n \frac{x-x_k}{x_j - x_k}                                                                              \\
        = \underbrace{\left( \prod_{k=0 \atop k \neq j}^n \frac{1}{x_j - x_k}\right)}_{=\beta_j} \left(\prod_{k=0 \atop k \neq j}^n x - x_k\right) \\
        = \beta_j \frac{1}{x - x_j} \prod_{k=0}^n x - x_k= \frac{\beta_j.w(x)}{x - x_j}
    \end{align}
    Substituting the result into $P_n$ we obtain the formulation:
    \begin{equation}
        P_n(x) = \sum_{j=0}^n \frac{f_j.\beta_j.w(x)}{x-x_j}
    \end{equation}
    Since $w(x)$ does not depend on the summation index, it can be extracted outside the sum:
    \begin{equation}
        P_n(x) = w(x) \sum_{j=0}^n \frac{\beta_j}{x-x_j}f_j
    \end{equation}
\end{solution}
\begin{problem}
Verify that
\begin{equation}
    1 = w(x).\sum_{j=0}^n \frac{\beta_j}{x - x_j}
\end{equation}
\end{problem}
\begin{solution}
    We can use the results from \exerciseref{ex:1} and consider $f(x) = 1$. We will use the fact that polynomials of degree $k \leq n$ overlap with $P_n$ (since we need $k+1$ points to fully describe the polynomial). So for $n \geq 0$ we have that $P_n(x) = 1$. Let's expand $P_n$:
    \begin{equation}
        1 = P_n(x) = w(x) \sum_{j=0}^n \frac{\beta_j}{x-x_j} \underbrace{f_j}_{=1} = w(x) \sum_{j=0}^n \frac{\beta_j}{x-x_j}
    \end{equation}
\end{solution}
\begin{problem}
A quadrature formula on the interval $[-1; 1]$ uses the quadrature points $x_0 = -\alpha$ and $x_1 = \alpha$, where $\alpha \in (0; -1]$:
\begin{equation}
    \int_{-1}^1 f(x) dx \approx w_0 f(-\alpha) + w_1 f(\alpha)
\end{equation}

The formula is required to be exact whenever $f$ is a polynomial of
degree 1 (i.e. $f(x) = a_0 + a_1 x$). Show that $w_0 = w_1 = 1$, independent of the value of $\alpha$.
\end{problem}
\begin{solution}
    Since the formula is required to be exact for a first-degree polynomial, we can solve the integral:
    \begin{align}
        \int_{-1}^1 f(x) dx = \int_{-1}^1 (a_0 + a_1 x) dx \\
        = (a_0 x + \frac{a_1}{2} x^2)\bigg\rvert_{-1}^1    \\
        = a_0 + \frac{a_1}{2} - (\frac{a_1}{2} - a_0) = 2.a_0
    \end{align}
    So now we can substitute $w_0 = w_1 = 1$ in the quadrature formula:
    \begin{align}
        w_0 f(-\alpha) + w_1 f(\alpha) = f(-\alpha) + f(\alpha) \\
        = a_0 - a_1.\alpha + a_0 + a_1.\alpha = 2.a_0
    \end{align}
    Indeed the formula is exact for polynomials of degree 1.
\end{solution}
\begin{problem}
Show that there is one particular value of $\alpha$ for which the formula is exact for all polynomials of degree 2. Find this $\alpha$.
\end{problem}
\begin{solution}
    Again we will solve the integral first:
    \begin{align}
        \int_{-1}^1 f(x) dx = \int_{-1}^1 (a_0 + a_1 x + a_2x^2) dx                 \\
        = (a_0 x + \frac{a_1}{2} x^2 + \frac{a_2}{3}x^3)\bigg\rvert_{-1}^1          \\
        = a_0 + \frac{a_1}{2} + \frac{a_2}{3} + a_0 - \frac{a_1}{2} + \frac{a_2}{3} \\
        = 2.a_0 + \frac{2}{3}a_2 \label{eq:quadrature-integral}
    \end{align}
    Let us assign $w_0 = w_1 = 1$ and evaluate the quadrature formula:
    \begin{align}
        w_0 f(-\alpha) + w_1 f(\alpha) = f(-\alpha) + f(\alpha)             \\
        = a_0 - a_1.\alpha + a_2.\alpha^2 + a_0 + a_1.\alpha + a_2.\alpha^2 \\
        = 2.a_0 + 2.a_2.\alpha^2 \label{eq:quadrature-formula}
    \end{align}
    It is evident that
    \begin{equation}
        \alpha = \sqrt{\frac{1}{3}}
    \end{equation}
    Equalizes the expressions in \eqref{eq:quadrature-integral} and \eqref{eq:quadrature-formula}
\end{solution}
\begin{problem}
The one-dimensional interpolation scheme can be applied to higher dimensions. Let the function $f(x, y) = e^x \sin y$ is given. We wish to construct a function of the form
\begin{equation}
    p(x, y) = c_0 + c_1x + c_2y + c_3xy + c_4x^2 + c_5y^2
\end{equation}
that interpolates $f(x, y)$ at $\vect{x_0, y_0}, \vect{x_1, y_1}, \vect{x_2, y_2}, \vect{x_3, y_3}, \vect{x_4, y_4}, \vect{x_5, y_5}$.
\end{problem}
\begin{solution}
    Again we denote $f_i = f(x_i, y_i)$

    We can setup the interpolation system as follows:
    \begin{equation}
        \begin{pmatrix}
            1 & x_0 & y_0 & x_0.y_0 & x_0^2 & y_0^2 \\
            1 & x_1 & y_1 & x_1.y_1 & x_1^2 & y_1^2 \\
            1 & x_2 & y_2 & x_2.y_2 & x_2^2 & y_2^2 \\
            1 & x_3 & y_3 & x_3.y_3 & x_3^2 & y_3^2 \\
            1 & x_4 & y_4 & x_4.y_4 & x_4^2 & y_4^2 \\
            1 & x_5 & y_5 & x_5.y_5 & x_5^2 & y_5^2
        \end{pmatrix}
        \begin{pmatrix}
            c_0 \\ c_1 \\ c_2 \\ c_3 \\ c_4 \\ c_5
        \end{pmatrix}
        =
        \begin{pmatrix}
            f_0 \\ f_1 \\ f_2 \\ f_3 \\ f_4 \\ f_5
        \end{pmatrix}
    \end{equation}
\end{solution}
\begin{problem}
    Write code to determine c when $f(x, y) = e^x \sin y$ and the $\vect{xi, yi}$ pairs take the values listed in the following table and report your value for $c$.
    \begin{table}[h]
        \centering
        \begin{tabular}{c|c c c c c c}
            \hline
            $j$ & 0 & 1 & 2 & 3 & 4 & 5 \\
            \hline
            $x_j$ & 0 & 0 & 1 & 1 & 2 & 2 \\
            $y_j$ & 0 & 2 & 0 & 2 & 1 & 3 \\
            \hline
        \end{tabular}
    \end{table}
\end{problem}
\begin{solution}
    
\end{solution}
\begin{remark}
    A good observation for the function $f$ is that it is odd function in $y$ - this would simplify the calculation and make the matrix $A$ ''symmetric'' in a sense that we would have to calculate half as many points or use the available points for a better approximation and use an appropriate formula for odd functions
\end{remark}
\begin{problem}
    Plot your model function $p(x, y)$ over $x \in [-1; 3], y \in [-1; 3]$. Compare this plot to the similar plot for $f (x, y)$. Please submit plots of both $p(x, y)$ and $f(x, y)$.
\end{problem}

% \printbibliography
\end{document}